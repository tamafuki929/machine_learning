# Computer Vision

## 1. History[^1]

* [x] seq2seqモデルによる時系列解釈の実現
RNNやその発展系であるLSTMは, 入力ベクトルの時系列性を認識し, 逐次的かつ再起的に学習を行うことで文脈の認識を可能とした. しかし, 学習に多大な時間が掛かること, 保持できる過去の情報が限られていることが課題として残った. また, 並列処理が可能なために, 計算効率において優れるCNNは, データの局所的な構造を捉えることはできる(耳, 目, 口元などパーツごとの特徴を認識する)が, 因果関係や位置関係といった時系列性を学習することはできない(局所構造と局所構造の関係性を学ぶことはできない). detectionにおいても, 画像の意味(画面構成, 位置情報, 文脈)を学習しているのではなく, フィルタ機能(局所構造の中で対象か対象でないかを判別)を学習していると考えられており, 自然言語処理や画像説明などの局所構造間の関係性が必要なタスクには適さない. 
seq2seqモデルは, 一般的にエンコーダーとデコーダーによって構成される. エンコーダーは入力を抽象化する機能を持ち, 自然言語処理タスクにおいては, 自然言語をより抽象的な文脈情報(言語間で共通する意味特徴量)に変換する役割を持つ. デコーダーは特徴量の具体化を行う機能を持ち, 抽象的な意味情報を特的のドメインや具体例へと変換する役割を果たす(自然言語処理では, 言語間で共通する意味情報から各国の言語への変換など). 
具体的な課題点としては, エンコーダーによって生成されるconetxt vectorが固定長であり, context vectorが長くなるに応じて, 計算資源の増大, 計算効率の悪化, 短期的情報の軽視, が発生する点が挙げられる. 

* [x] Transformer[^2][^3][^4][^5][^6]
TransformerはAttentionと呼ばれる新たな時系列を考慮した特徴量抽出手法によって, seq2seqモデルの学習効率を100倍以上に向上した. 計算効率の向上はより大規模なデータを用いた学習を可能とし, 結果的に飛躍的に精度が向上している. 

[^1]: https://aru47.hatenablog.com/entry/2020/08/18/175711

[^2]: query, key, valueが分かりやすく解説されている.
https://omathin.com/what-is-attention-1/

[^3]: 深層学習界の大前提Transformerの論文解説！  
Trasformerの全体像が詳しく分かりやすく説明されている。  
https://qiita.com/omiita/items/07e69aef6c156d23c538#151-%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%81%A8%E3%83%90%E3%83%83%E3%83%81

[^4]: Attention is all you needの解説  
Attentionとは何かを中心に説明されている。tranformer自体の解説は上記文献を参考にした方が良さそう。  
https://www.acceluniverse.com/blog/developers/2019/08/attention.html

[^5]: RNNからTransformerまでの歴史を辿る ～DNNを使ったNLPを浅く広く勉強～
https://aru47.hatenablog.com/entry/2020/08/18/175711

[^6]: Transformerを実装する
https://qiita.com/gensal/items/e1c4a34dbfd0d7449099