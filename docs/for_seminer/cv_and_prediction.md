# CVとtestデータのpredictについて

## Abstract
cvを用いたtrainデータにおける評価を行なったのちに, testデータにおける予測を行う際, 
1. 最適なパラメータと全trainデータで学習したモデルを使用
2. cv時の挙動を再現するため, 各foldで学習したモデルの平均を使用

の二種類が考えられる. 

cvでは実際に何を行なっているのかを考え, それを踏まえた上で, 1, 2どちらの方法が適切であるかを考察する. 

## TL;DR

* [x] Pattern1は訓練時と推論時の分布の差異が小さい場合のみ有効. 
* [x] Pattern2は, 訓練時と推論時の分布が異なる場合でも, cvの際に推論時の分布をうまく再現することで, 有効な精度推定を行うことが可能. 

## What is the CV validating?
CVは, 使用する予測アルゴリズム, 及びそのパラメータ, 訓練データを入力とし, それらを組み合わせて得られる予測モデルが未知のデータに対してどの程度の精度が得られるかを検証する手法である. 

単純なKfoldCVでは, 訓練データを複数個に分割し(一つ一つをfoldと呼ぶ), それらを学習用と評価用に二分する. 全てのfoldが一回ずつ評価用に, 評価用以外が学習用になるように, fold数回の学習と評価が行われる. 
つまり, 訓練データ全体を母集団としたデータ分布において, 学習用データ集合と評価用データ集合を偏りなくサンプリングし評価することで, 訓練データ全体を使用した際の未知のデータに対する予測性能を統計的に推定していると考えられる. 
そのため, 推定精度は, 訓練データの分布と推論時(未知のデータ)の分布の類似度(一致度), もしくは訓練データは真のデータ母集団から偏りなくサンプリングされたか, に大きく左右される. 

訓練データの偏りや推論時との分布の違いを見抜くためには, テスト時の分布と比較する方法と, ドメイン知識と照らし合わせる方法が存在する. 
前者は分析コンペや, 時系列データ分析など, 推論時の分布を入手可能な場合に有効である. この際は, 訓練データを用いて, 予測時の分布をうまく再現するように学習やcv設計を行う必要がある. 
後者は実務など, 推論時のデータが入手不可能な場合に有効である. ドメイン知識と照らし合わせて, 訓練データがそれらをうまく表現しているかを確認することで, 偏りや今後の分布の変遷を推定することができる. 

## Compare Pattern 1 and Patttern 2
パターン1は, 訓練データ全てを使用してモデルを学習するため, 訓練時と推論時の分布が類似している場合, cvの結果は推論時の予測性能をうまく推定することができる. 

しかし, 訓練時と推論時の分布が異なる場合, 単純に訓練データ全てを使用しても, 推論時の精度をうまく推定することはできない. この場合, CVを行う時点で, 予測時の分布を再現できるように設計する必要がある. 
この場合, 自身で定義した複数のクラスタからの層化サンプリングなどを用いて, 推論時の分布に近いfoldを複数設計することになる. 

そのため, cv後の推論用モデルの訓練においても, 同様の分布を持つデータを使用する必要がある. 
そのため, 単純に全データを使用して学習するというよりも, cv時と同じ分布となるようなデータセットを訓練データ全体から複数個サンプリングし, それらで学習したモデルの平均を使用することが必要である. 
この際, パターン2のように, cv時のfoldをそのまま使用しても良いが, 個々のモデルを構築するためのデータはfold数に反比例するため, 全データからサンプリングを行なった場合と比較すると, 推定精度が悪化する可能性がある. 

## Conclusion
* [x] Pattern1は, 訓練コストが低く, 訓練時と推論時の分布の差異が小さい場合に有効. 
* [x] Pattern2は, 訓練時と推論時の分布が異なる場合でも, cvの際に推論時の分布をうまく再現することで, 有効な精度推定を行うことが可能. しかし, 推論時は, out of foldsを意識しないサンプリングを行なったデータセット群によって訓練したモデルの平均を使用した方が推定精度は高くなると考えられる. 